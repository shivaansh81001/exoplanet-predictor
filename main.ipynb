{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWfoh6jayHV8uI24pS7OmT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivaansh81001/cmput-466-mini-project/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "ERKokxgmKP5e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datascience import *\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 112\n",
        "\n",
        "TRAIN_PERC=0.6\n",
        "VAL_PERC=0.2\n",
        "TEST_PERC=0.2"
      ],
      "metadata": {
        "id": "Z8Pf6RsenuXb"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test imports\n",
        "arr=[0,1,2,3,4,5,6,7,8,9]\n",
        "print(\"numpy working \",np.array(arr))\n",
        "print(\"pandas working \",pd.array(arr))\n",
        "Table().with_column(\"test\",np.array(arr)).show(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "s07lM57HMGPU",
        "outputId": "06a22b27-3972-421e-8824-358e82426caa"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy working  [0 1 2 3 4 5 6 7 8 9]\n",
            "pandas working  <IntegerArray>\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Length: 10, dtype: Int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>test</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>0   </td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>\n",
              "<p>... (9 rows omitted)</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=Table().read_table('cumulative.csv')\n",
        "##data.show(5)\n",
        "data=data.drop([\"koi_tce_delivname\",\"koi_pdisposition\",\"kepler_name\",\"rowid\",\"kepid\",\"kepoi_name\",\"koi_teq_err1\",\"koi_teq_err2\",\"koi_score\"])\n",
        "\n",
        "for col in data.labels:\n",
        "  data=data.where(col,are.not_equal_to('nan'))\n",
        "  data=data.where(col,are.not_equal_to(float(np.nan)))\n",
        "\n",
        "#print(type(data.take(99).column('koi_tce_plnt_num')[0]),data.take(99).column('koi_tce_plnt_num')[0])\n",
        "\n",
        "data.show(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "xcaLpQG-OhCy",
        "outputId": "4426f174-a9f5-477d-b46e-34740fc2024d"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>koi_disposition</th> <th>koi_fpflag_nt</th> <th>koi_fpflag_ss</th> <th>koi_fpflag_co</th> <th>koi_fpflag_ec</th> <th>koi_period</th> <th>koi_period_err1</th> <th>koi_period_err2</th> <th>koi_time0bk</th> <th>koi_time0bk_err1</th> <th>koi_time0bk_err2</th> <th>koi_impact</th> <th>koi_impact_err1</th> <th>koi_impact_err2</th> <th>koi_duration</th> <th>koi_duration_err1</th> <th>koi_duration_err2</th> <th>koi_depth</th> <th>koi_depth_err1</th> <th>koi_depth_err2</th> <th>koi_prad</th> <th>koi_prad_err1</th> <th>koi_prad_err2</th> <th>koi_teq</th> <th>koi_insol</th> <th>koi_insol_err1</th> <th>koi_insol_err2</th> <th>koi_model_snr</th> <th>koi_tce_plnt_num</th> <th>koi_steff</th> <th>koi_steff_err1</th> <th>koi_steff_err2</th> <th>koi_slogg</th> <th>koi_slogg_err1</th> <th>koi_slogg_err2</th> <th>koi_srad</th> <th>koi_srad_err1</th> <th>koi_srad_err2</th> <th>ra</th> <th>dec</th> <th>koi_kepmag</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>CONFIRMED      </td> <td>0            </td> <td>0            </td> <td>0            </td> <td>0            </td> <td>9.48804   </td> <td>2.775e-05      </td> <td>-2.775e-05     </td> <td>170.539    </td> <td>0.00216         </td> <td>-0.00216        </td> <td>0.146     </td> <td>0.318          </td> <td>-0.146         </td> <td>2.9575      </td> <td>0.0819           </td> <td>-0.0819          </td> <td>615.8    </td> <td>19.5          </td> <td>-19.5         </td> <td>2.26    </td> <td>0.26         </td> <td>-0.15        </td> <td>793    </td> <td>93.59    </td> <td>29.45         </td> <td>-16.65        </td> <td>35.8         </td> <td>1               </td> <td>5455     </td> <td>81            </td> <td>-81           </td> <td>4.467    </td> <td>0.064         </td> <td>-0.096        </td> <td>0.927   </td> <td>0.105        </td> <td>-0.061       </td> <td>291.934</td> <td>48.1417</td> <td>15.347    </td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>CONFIRMED      </td> <td>0            </td> <td>0            </td> <td>0            </td> <td>0            </td> <td>54.4184   </td> <td>0.0002479      </td> <td>-0.0002479     </td> <td>162.514    </td> <td>0.00352         </td> <td>-0.00352        </td> <td>0.586     </td> <td>0.059          </td> <td>-0.443         </td> <td>4.507       </td> <td>0.116            </td> <td>-0.116           </td> <td>874.8    </td> <td>35.5          </td> <td>-35.5         </td> <td>2.83    </td> <td>0.32         </td> <td>-0.19        </td> <td>443    </td> <td>9.11     </td> <td>2.87          </td> <td>-1.62         </td> <td>25.8         </td> <td>2               </td> <td>5455     </td> <td>81            </td> <td>-81           </td> <td>4.467    </td> <td>0.064         </td> <td>-0.096        </td> <td>0.927   </td> <td>0.105        </td> <td>-0.061       </td> <td>291.934</td> <td>48.1417</td> <td>15.347    </td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>FALSE POSITIVE </td> <td>0            </td> <td>1            </td> <td>0            </td> <td>0            </td> <td>19.8991   </td> <td>1.494e-05      </td> <td>-1.494e-05     </td> <td>175.85     </td> <td>0.000581        </td> <td>-0.000581       </td> <td>0.969     </td> <td>5.126          </td> <td>-0.077         </td> <td>1.7822      </td> <td>0.0341           </td> <td>-0.0341          </td> <td>10829    </td> <td>171           </td> <td>-171          </td> <td>14.6    </td> <td>3.92         </td> <td>-1.31        </td> <td>638    </td> <td>39.3     </td> <td>31.04         </td> <td>-10.49        </td> <td>76.3         </td> <td>1               </td> <td>5853     </td> <td>158           </td> <td>-176          </td> <td>4.544    </td> <td>0.044         </td> <td>-0.176        </td> <td>0.868   </td> <td>0.233        </td> <td>-0.078       </td> <td>297.005</td> <td>48.1341</td> <td>15.436    </td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>FALSE POSITIVE </td> <td>0            </td> <td>1            </td> <td>0            </td> <td>0            </td> <td>1.73695   </td> <td>2.63e-07       </td> <td>-2.63e-07      </td> <td>170.308    </td> <td>0.000115        </td> <td>-0.000115       </td> <td>1.276     </td> <td>0.115          </td> <td>-0.092         </td> <td>2.40641     </td> <td>0.00537          </td> <td>-0.00537         </td> <td>8079.2   </td> <td>12.8          </td> <td>-12.8         </td> <td>33.46   </td> <td>8.5          </td> <td>-2.83        </td> <td>1395   </td> <td>891.96   </td> <td>668.95        </td> <td>-230.35       </td> <td>505.6        </td> <td>1               </td> <td>5805     </td> <td>157           </td> <td>-174          </td> <td>4.564    </td> <td>0.053         </td> <td>-0.168        </td> <td>0.791   </td> <td>0.201        </td> <td>-0.067       </td> <td>285.535</td> <td>48.2852</td> <td>15.597    </td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>\n",
              "<p>... (9560 rows omitted)</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.to_df().dropna()\n",
        "data=Table().from_df(data)\n",
        "data=data.shuffle()\n",
        "#data.show(10)\n",
        "\n",
        "target = (data.column(\"koi_disposition\")==\"CONFIRMED\").astype(int)\n",
        "X = data.drop(\"koi_disposition\").to_df()"
      ],
      "metadata": {
        "id": "E2lOSu7vlHCK"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_report()"
      ],
      "metadata": {
        "id": "Pj9dXobCxS9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(t, t_hat):\n",
        "    \"\"\"\n",
        "    Calculate accuracy,\n",
        "    \"\"\"\n",
        "    #print(t,t_hat)\n",
        "    acc=np.mean(t==t_hat)*100\n",
        "    #print(\"accuracy\",acc)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "0zIPk9gar2an"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model(X_test,t_test):\n",
        "  k = len(np.unique(t_test))\n",
        "  #print(k)\n",
        "  np.random.seed(RANDOM_SEED)\n",
        "  t_hat=np.random.choice(np.unique(t_test),size=len(X_test),replace=True)\n",
        "\n",
        "  return t_hat\n",
        ""
      ],
      "metadata": {
        "id": "-JwbLNsb5-FD"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
        "\n",
        "def train_logistic_regression(X, t):\n",
        "    \"\"\"\n",
        "    Given data, train your logistic classifier.\n",
        "    Return weight and bias\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    m,n=X.shape\n",
        "    w=np.zeros(n)\n",
        "    b=0\n",
        "\n",
        "    for i in range(1000):\n",
        "        z=np.dot(X,w)+b\n",
        "        t_hat=sigmoid(z)\n",
        "        dw=(1/m)*np.dot(X.T,(t_hat-t))\n",
        "        db=(1/m)*np.sum(t_hat-t)\n",
        "        w-=0.1*dw\n",
        "        b-=0.1*db\n",
        "    #print(w,b)\n",
        "\n",
        "    return w, b\n",
        "\n",
        "def predict_logistic_regression(X, w, b):\n",
        "    \"\"\"\n",
        "    Generate predictions by your logistic classifier.\n",
        "    \"\"\"\n",
        "    temp=1/(1+np.exp(-(X@w+b)))\n",
        "    t=(temp>=0.5).astype(int)\n",
        "    return t"
      ],
      "metadata": {
        "id": "_9nwH34CrYsf"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_SVM(X_train,t_train):\n",
        "  svm =SVC(kernel='rbf',C=1.0,random_state= RANDOM_SEED)\n",
        "  svm.fit(X_train,t_train)\n",
        "  return svm\n",
        "\n",
        "def predict_SVM(model_fit,X_val):\n",
        "  t_hat=model_fit.predict(X_val)\n",
        "  return t_hat\n"
      ],
      "metadata": {
        "id": "NHQntFZnNxMy"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_MLP(X_train,t_train):\n",
        "  mlp=MLPClassifier(hidden_layer_sizes=(64,32),activation='relu', max_iter=300, random_state=42)\n",
        "  mlp.fit(X_train,t_train)\n",
        "  return mlp\n",
        "\n",
        "def predict_MLP(mlp,X_val):\n",
        "  t_hat=mlp.predict(X_val)\n",
        "  return t_hat\n"
      ],
      "metadata": {
        "id": "Rz6zMcW1Bvo3"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "total_rows=len(target)\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "X_train, X_temp, t_train, t_temp = train_test_split(X, target, test_size=(1 - TRAIN_PERC), random_state=RANDOM_SEED,stratify=target)\n",
        "X_val, X_test, t_val, t_test = train_test_split(X_temp, t_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=t_temp)"
      ],
      "metadata": {
        "id": "Vh-YxbbhAPzX"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "\n",
        "  t_hat_test_base=baseline_model(X_test,t_test)\n",
        "  print(\"Accuracy of baseline on test set: \", get_accuracy(t_hat_test_base, t_test))\n",
        "\n",
        "  ##################### LOGISTIC REGRESSION #####################\n",
        "  w_log, b_log = train_logistic_regression(X_train, t_train)\n",
        "  t_hat_val_log = predict_logistic_regression(X_val, w_log, b_log)\n",
        "  print(\"Accuracy of logistic regression on validation set: \", get_accuracy(t_hat_val_log, t_val))\n",
        "  t_hat_test_log = predict_logistic_regression(X_test, w_log, b_log)\n",
        "  print(\"Accuracy of logistic regression on test set: \", get_accuracy(t_hat_test_log, t_test))\n",
        "  ##################### LOGISTIC REGRESSION #####################\n",
        "\n",
        "\n",
        "  ##################### SVM #####################\n",
        "  model_fit = train_SVM(X_train,t_train)\n",
        "  t_hat_svm_val =predict_SVM(model_fit,X_val)\n",
        "  print(\"Accuracy of SVM on validation set: \", get_accuracy(t_hat_svm_val, t_val))\n",
        "  t_hat_svm_test= predict_SVM(model_fit,X_test)\n",
        "  print(\"Accuracy of SVM on test set: \", get_accuracy(t_hat_svm_test, t_test))\n",
        "  ##################### SVM #####################\n",
        "\n",
        "\n",
        "  ##################### MLP #####################\n",
        "  mlp= train_MLP(X_train,t_train)\n",
        "  t_hat_mlp_val=predict_MLP(mlp,X_val)\n",
        "  print(\"Accuracy of MLP on validation set: \", get_accuracy(t_hat_mlp_val, t_val))\n",
        "  t_hat_mlp_test= predict_MLP(mlp,X_test)\n",
        "  print(\"Accuracy of MLP on test set: \", get_accuracy(t_hat_mlp_test, t_test))\n",
        "  ##################### SVM #####################\n",
        "\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6bzV6jGra9l",
        "outputId": "49dc674f-7b19-4529-b890-fc068941dc34"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of baseline on test set:  48.3704974271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of logistic regression on validation set:  74.213836478\n",
            "Accuracy of logistic regression on test set:  74.213836478\n",
            "Accuracy of SVM on validation set:  74.0423098914\n",
            "Accuracy of SVM on test set:  73.9851343625\n",
            "Accuracy of MLP on validation set:  84.619782733\n",
            "Accuracy of MLP on test set:  84.162378502\n"
          ]
        }
      ]
    }
  ]
}