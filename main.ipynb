{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZu30v9BvEHQL/lgsatD+S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivaansh81001/cmput-466-mini-project/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ERKokxgmKP5e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datascience import *\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 420\n",
        "\n",
        "TRAIN_PERC=0.6\n",
        "VAL_PERC=0.2\n",
        "TEST_PERC=0.2"
      ],
      "metadata": {
        "id": "Z8Pf6RsenuXb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test imports\n",
        "arr=[0,1,2,3,4,5,6,7,8,9]\n",
        "print(\"numpy working \",np.array(arr))\n",
        "print(\"pandas working \",pd.array(arr))\n",
        "Table().with_column(\"test\",np.array(arr)).show(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "s07lM57HMGPU",
        "outputId": "9cc79268-1cfa-49e2-9801-5ad7ca912fcb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy working  [0 1 2 3 4 5 6 7 8 9]\n",
            "pandas working  <IntegerArray>\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Length: 10, dtype: Int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>test</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>0   </td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>\n",
              "<p>... (9 rows omitted)</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=Table().read_table('cumulative.csv')\n",
        "##data.show(5)\n",
        "data=data.drop([\"koi_tce_delivname\",\"koi_pdisposition\",\"kepler_name\",\"rowid\",\"kepid\",\"kepoi_name\",\"koi_teq_err1\",\"koi_teq_err2\",\"koi_score\"])\n",
        "\n",
        "for col in data.labels:\n",
        "  data=data.where(col,are.not_equal_to('nan'))\n",
        "  data=data.where(col,are.not_equal_to(float(np.nan)))\n",
        "\n",
        "#print(type(data.take(99).column('koi_tce_plnt_num')[0]),data.take(99).column('koi_tce_plnt_num')[0])\n",
        "\n",
        "#data.show(4)"
      ],
      "metadata": {
        "id": "xcaLpQG-OhCy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.to_df().dropna()\n",
        "data=Table().from_df(data)\n",
        "\n",
        "#data.group('koi_disposition').show(5)\n",
        "#data.show(10)\n",
        "num_false=data.where('koi_disposition',are.equal_to('FALSE POSITIVE')).num_rows\n",
        "\n",
        "\n",
        "false_data=data.where('koi_disposition',are.equal_to('FALSE POSITIVE')).sample(k=int(0.5*num_false))\n",
        "##false_data.show(3)\n",
        "\n",
        "\n",
        "confirmed_data=data.where('koi_disposition',are.equal_to('CONFIRMED'))\n",
        "#confirmed_data.show(3)\n",
        "\n",
        "data= false_data.append(confirmed_data).shuffle()\n",
        "data=data.shuffle()\n",
        "\n",
        "\n",
        "target = (data.column(\"koi_disposition\")==\"CONFIRMED\").astype(int)\n",
        "X = data.drop(\"koi_disposition\").to_df()"
      ],
      "metadata": {
        "id": "E2lOSu7vlHCK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_report(t_true,t_pred):\n",
        "  return {\n",
        "        'Accuracy': accuracy_score(t_true, t_pred),\n",
        "        'Precision': precision_score(t_true, t_pred),\n",
        "        'Recall': recall_score(t_true, t_pred),\n",
        "        'F1-Score': f1_score(t_true, t_pred)\n",
        "    }"
      ],
      "metadata": {
        "id": "Pj9dXobCxS9r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(t, t_hat):\n",
        "    \"\"\"\n",
        "    Calculate accuracy,\n",
        "    \"\"\"\n",
        "    #print(t,t_hat)\n",
        "    acc=np.mean(t==t_hat)*100\n",
        "    #print(\"accuracy\",acc)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "0zIPk9gar2an"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model(X_test,t_test):\n",
        "  k = len(np.unique(t_test))\n",
        "  #print(k)\n",
        "  np.random.seed(RANDOM_SEED)\n",
        "  t_hat=np.random.choice(np.unique(t_test),size=len(X_test),replace=True)\n",
        "\n",
        "  return t_hat\n"
      ],
      "metadata": {
        "id": "-JwbLNsb5-FD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-np.clip(z, -400, 400)))\n",
        "\n",
        "def train_logistic_regression(X, t):\n",
        "    \"\"\"\n",
        "    Given data, train your logistic classifier.\n",
        "    Return weight and bias\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    m,n=X.shape\n",
        "    w=np.zeros(n)\n",
        "    b=0\n",
        "\n",
        "    for i in range(1000):\n",
        "        z=np.dot(X,w)+b\n",
        "        t_hat=sigmoid(z)\n",
        "        dw=(1/m)*np.dot(X.T,(t_hat-t))\n",
        "        db=(1/m)*np.sum(t_hat-t)\n",
        "        w-=0.1*dw\n",
        "        b-=0.1*db\n",
        "    #print(w,b)\n",
        "\n",
        "    return w, b\n",
        "\n",
        "def predict_logistic_regression(X, w, b):\n",
        "    \"\"\"\n",
        "    Generate predictions by your logistic classifier.\n",
        "    \"\"\"\n",
        "    temp=1/(1+np.exp(-(X@w+b)))\n",
        "    t=(temp>=0.5).astype(int)\n",
        "    return t"
      ],
      "metadata": {
        "id": "_9nwH34CrYsf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_SVM(X_train,t_train):\n",
        "  svm =SVC(kernel='rbf',C=10,random_state= RANDOM_SEED,gamma=0.001,class_weight='balanced')\n",
        "  svm.fit(X_train,t_train)\n",
        "  return svm\n",
        "\n",
        "def predict_SVM(model_fit,X_val):\n",
        "  t_hat=model_fit.predict(X_val)\n",
        "  return t_hat\n"
      ],
      "metadata": {
        "id": "NHQntFZnNxMy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_MLP(X_train,t_train):\n",
        "  mlp=MLPClassifier(hidden_layer_sizes=(64,32),activation='relu', max_iter=300, random_state=42)\n",
        "  mlp.fit(X_train,t_train)\n",
        "  return mlp\n",
        "\n",
        "def predict_MLP(mlp,X_val):\n",
        "  t_hat=mlp.predict(X_val)\n",
        "  return t_hat\n"
      ],
      "metadata": {
        "id": "Rz6zMcW1Bvo3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "total_rows=len(target)\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "X_train, X_temp, t_train, t_temp = train_test_split(X, target, test_size=(1 - TRAIN_PERC), random_state=RANDOM_SEED,stratify=target)\n",
        "X_val, X_test, t_val, t_test = train_test_split(X_temp, t_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=t_temp)"
      ],
      "metadata": {
        "id": "Vh-YxbbhAPzX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "  ##################### BASELINE #####################\n",
        "  t_hat_test_base=baseline_model(X_test,t_test)\n",
        "  print(\"Accuracy of baseline on test set: \", get_accuracy(t_hat_test_base, t_test))\n",
        "  print(pd.DataFrame({\n",
        "      \"Test Set\": generate_report(t_test,t_hat_test_base)\n",
        "                         }))\n",
        "  ##################### BASELINE #####################\n",
        "\n",
        "\n",
        "\n",
        "  ##################### LOGISTIC REGRESSION #####################\n",
        "  w_log, b_log = train_logistic_regression(X_train, t_train)\n",
        "  t_hat_val_log = predict_logistic_regression(X_val, w_log, b_log)\n",
        "  print(\"Accuracy of logistic regression on validation set: \", get_accuracy(t_hat_val_log, t_val))\n",
        "  t_hat_test_log = predict_logistic_regression(X_test, w_log, b_log)\n",
        "  print(\"Accuracy of logistic regression on test set: \", get_accuracy(t_hat_test_log, t_test))\n",
        "  print(pd.DataFrame({\n",
        "      \"Validation Set\": generate_report(t_val, t_hat_val_log),\n",
        "      \"Test Set\": generate_report(t_test,t_hat_test_log)\n",
        "                         }))\n",
        "  ##################### LOGISTIC REGRESSION #####################\n",
        "\n",
        "\n",
        "\n",
        "  ##################### SVM #####################\n",
        "  model_fit = train_SVM(X_train,t_train)\n",
        "  #print(\"Best params\", model_fit.best_params_)\n",
        "  t_hat_svm_val =predict_SVM(model_fit,X_val)\n",
        "  print(\"Accuracy of SVM on validation set: \", get_accuracy(t_hat_svm_val, t_val))\n",
        "  t_hat_svm_test= predict_SVM(model_fit,X_test)\n",
        "  print(\"Accuracy of SVM on test set: \", get_accuracy(t_hat_svm_test, t_test))\n",
        "  print(pd.DataFrame({\n",
        "      \"Validation Set\": generate_report(t_val, t_hat_svm_val),\n",
        "      \"Test Set\": generate_report(t_test,t_hat_svm_test)\n",
        "                         }))\n",
        "  ##################### SVM #####################\n",
        "\n",
        "\n",
        "\n",
        "  ##################### MLP #####################\n",
        "  mlp= train_MLP(X_train,t_train)\n",
        "  t_hat_mlp_val=predict_MLP(mlp,X_val)\n",
        "  print(\"Accuracy of MLP on validation set: \", get_accuracy(t_hat_mlp_val, t_val))\n",
        "  t_hat_mlp_test= predict_MLP(mlp,X_test)\n",
        "  print(\"Accuracy of MLP on test set: \", get_accuracy(t_hat_mlp_test, t_test))\n",
        "  print(pd.DataFrame({\n",
        "      \"Validation Set\": generate_report(t_val, t_hat_mlp_val),\n",
        "      \"Test Set\": generate_report(t_test,t_hat_mlp_test)\n",
        "                         }))\n",
        "  ##################### SVM #####################\n",
        "\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6bzV6jGra9l",
        "outputId": "17742a80-db45-4b57-c32b-d26c3cb26d1a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of baseline on test set:  48.9337822671\n",
            "           Test Set\n",
            "Accuracy   0.489338\n",
            "Precision  0.500000\n",
            "Recall     0.474725\n",
            "F1-Score   0.487035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of logistic regression on validation set:  71.3483146067\n",
            "Accuracy of logistic regression on test set:  71.3804713805\n",
            "           Validation Set  Test Set\n",
            "Accuracy         0.713483  0.713805\n",
            "Precision        0.890196  0.862319\n",
            "Recall           0.500000  0.523077\n",
            "F1-Score         0.640339  0.651163\n",
            "Accuracy of SVM on validation set:  64.4943820225\n",
            "Accuracy of SVM on test set:  64.1975308642\n",
            "           Validation Set  Test Set\n",
            "Accuracy         0.644944  0.641975\n",
            "Precision        0.589610  0.588083\n",
            "Recall           1.000000  0.997802\n",
            "F1-Score         0.741830  0.740016\n",
            "Accuracy of MLP on validation set:  88.6516853933\n",
            "Accuracy of MLP on test set:  90.7968574635\n",
            "           Validation Set  Test Set\n",
            "Accuracy         0.886517  0.907969\n",
            "Precision        0.937965  0.947242\n",
            "Recall           0.832599  0.868132\n",
            "F1-Score         0.882147  0.905963\n"
          ]
        }
      ]
    }
  ]
}